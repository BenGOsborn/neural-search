{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f11ac2e",
   "metadata": {},
   "source": [
    "# Neural Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40edb412",
   "metadata": {},
   "source": [
    "An AI powered search engine using Transformers, K-Means, and Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e551a357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "285f15ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef9806d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket_name = sess.default_bucket()\n",
    "role_name = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_prefix = \"neural-search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d700690e",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dc81f0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>release_date</th>\n",
       "      <th>revenue</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>[{'id': 16, 'name': 'Animation'}, {'id': 35, '...</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>1995-10-30</td>\n",
       "      <td>373554033.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   adult                              belongs_to_collection    budget  \\\n",
       "0  False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "\n",
       "                                              genres  \\\n",
       "0  [{'id': 16, 'name': 'Animation'}, {'id': 35, '...   \n",
       "\n",
       "                               homepage   id    imdb_id original_language  \\\n",
       "0  http://toystory.disney.com/toy-story  862  tt0114709                en   \n",
       "\n",
       "  original_title                                           overview  ...  \\\n",
       "0      Toy Story  Led by Woody, Andy's toys live happily in his ...  ...   \n",
       "\n",
       "  release_date      revenue runtime                          spoken_languages  \\\n",
       "0   1995-10-30  373554033.0    81.0  [{'iso_639_1': 'en', 'name': 'English'}]   \n",
       "\n",
       "     status  tagline      title  video vote_average vote_count  \n",
       "0  Released      NaN  Toy Story  False          7.7     5415.0  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location = f\"s3://{bucket_name}/{bucket_prefix}/data/movies_metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(data_location)\n",
    "\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ce819600",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    Led by Woody, Andy's toys live happily in his ...\n",
       "Name: overview, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "overview_df = df[\"overview\"]\n",
    "\n",
    "overview_df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0a6e63a",
   "metadata": {},
   "source": [
    "## Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "3ce1ac9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "from itertools import combinations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1005b4c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f99517944b4540c88463fd67319e998a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/232k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f88b22eee5684a1a82b420f967164664",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a1aa6b75ead48f98625cd16bafad792",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/570 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d52f14db3b9f4e2d9df981705df4ec0e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "9c1cb34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    \n",
    "    pooled = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    return torch.nn.functional.normalize(pooled, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "c5dd1f20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 768])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_text = [\"The moon looks beautiful today\", \"I am going for a walk today\", \"Do you like the moon?\", \"Those are some tasty sandwiches\", \"Why is that castle old?\"]\n",
    "\n",
    "encoded_input = tokenizer(sample_text, padding=True, truncation=True, return_tensors=\"pt\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    out = model(**encoded_input)\n",
    "\n",
    "sentence_embeddings = mean_pooling(out, encoded_input[\"attention_mask\"])\n",
    "\n",
    "sentence_embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6a530633",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'The moon looks beautiful today', 'I am going for a walk today', similarity=0.6303966045379639\n",
      "'The moon looks beautiful today', 'Do you like the moon?', similarity=0.7295293807983398\n",
      "'The moon looks beautiful today', 'Those are some tasty sandwiches', similarity=0.6001173257827759\n",
      "'The moon looks beautiful today', 'Why is that castle old?', similarity=0.6742875576019287\n",
      "'I am going for a walk today', 'Do you like the moon?', similarity=0.6220574378967285\n",
      "'I am going for a walk today', 'Those are some tasty sandwiches', similarity=0.5492238402366638\n",
      "'I am going for a walk today', 'Why is that castle old?', similarity=0.5797369480133057\n",
      "'Do you like the moon?', 'Those are some tasty sandwiches', similarity=0.5650840401649475\n",
      "'Do you like the moon?', 'Why is that castle old?', similarity=0.7014718055725098\n",
      "'Those are some tasty sandwiches', 'Why is that castle old?', similarity=0.5975286364555359\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity_model = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "tuples = combinations(list(range(sentence_embeddings.size()[0])), 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, j in tuples:\n",
    "        similarity = cosine_similarity_model(sentence_embeddings[i], sentence_embeddings[j])\n",
    "        print(f\"'{sample_text[i]}', '{sample_text[j]}', similarity={similarity}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "6b19912d",
   "metadata": {},
   "source": [
    "So now we need to come up with a model pipeline where we first take the text from pandas, move it to the GPU, run the model on all of the text in batches, record the vectors in the dataframe, perform KMeansClustering with a trained model, create labels for the dataframe, then for a given piece of text get its embeddings and its cluster, then perform cosine similarity search between all elements in the cluster and then rank accordingly"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
