{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "62452432",
   "metadata": {},
   "source": [
    "# Neural Search"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d836799a",
   "metadata": {},
   "source": [
    "An AI powered search engine using Transformers, K-Means, and Cosine Similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1c209f8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: You are using pip version 22.0.4; however, version 22.3.1 is available.\n",
      "You should consider upgrading via the '/home/ec2-user/anaconda3/envs/pytorch_p38/bin/python -m pip install --upgrade pip' command.\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a1ae7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "144cb5cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = sagemaker.Session()\n",
    "\n",
    "bucket_name = sess.default_bucket()\n",
    "role_name = sagemaker.get_execution_role()\n",
    "\n",
    "bucket_prefix = \"neural-search\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bee29c",
   "metadata": {},
   "source": [
    "## Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "dea9f618",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/pytorch_p38/lib/python3.8/site-packages/IPython/core/interactiveshell.py:3524: DtypeWarning: Columns (10) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  exec(code_obj, self.user_global_ns, self.user_ns)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                           overview\n",
       "0  Toy Story  Led by Woody, Andy's toys live happily in his ...\n",
       "1    Jumanji  When siblings Judy and Peter discover an encha..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_location = f\"s3://{bucket_name}/{bucket_prefix}/data/movies_metadata.csv\"\n",
    "\n",
    "df = pd.read_csv(data_location)[[\"title\", \"overview\"]]\n",
    "df = df[df[\"overview\"].notna()]\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f52d50f6",
   "metadata": {},
   "source": [
    "## Load embedding model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95e08bfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import BertModel, BertTokenizer\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "13a2f596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.bias']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "model_name = \"bert-base-uncased\"\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "\n",
    "text_model = BertModel.from_pretrained(model_name)\n",
    "cosine_similarity_model = torch.nn.CosineSimilarity(dim=0, eps=1e-6)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f9819df9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_pooling(model_output, attention_mask):\n",
    "    token_embeddings = model_output.last_hidden_state\n",
    "    input_mask_expanded = (\n",
    "        attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
    "    )\n",
    "    \n",
    "    pooled = torch.sum(token_embeddings * input_mask_expanded, 1) / torch.clamp(input_mask_expanded.sum(1), min=1e-9)\n",
    "    \n",
    "    return torch.nn.functional.normalize(pooled, p=2, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a72ecb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_embeddings(text, tokenizer, model):\n",
    "    encoded_input = tokenizer(\n",
    "        text,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    encoded_input = {k: v.to(device) for k, v in encoded_input.items()}\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        model_output = model(**encoded_input)\n",
    "    \n",
    "    return mean_pooling(model_output, encoded_input[\"attention_mask\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56f108cf",
   "metadata": {},
   "source": [
    "### Example embedding similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "ea063fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Andy is going to the beach on Sunday with his friends', 'Mandy is going to the movies Tuesday with her Mum', similarity=0.8401806950569153\n",
      "'Andy is going to the beach on Sunday with his friends', 'The cargo ship sailed through the night', similarity=0.561195433139801\n",
      "'Mandy is going to the movies Tuesday with her Mum', 'The cargo ship sailed through the night', similarity=0.5241331458091736\n"
     ]
    }
   ],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "sample_text = [\n",
    "    \"Andy is going to the beach on Sunday with his friends\",\n",
    "    \"Mandy is going to the movies Tuesday with her Mum\",\n",
    "    \"The cargo ship sailed through the night\",\n",
    "]\n",
    "\n",
    "sample_embeddings = create_embeddings(sample_text, tokenizer, text_model).cpu().numpy()\n",
    "\n",
    "tuples = combinations(list(range(sentence_embeddings.size()[0])), 2)\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, j in tuples:\n",
    "        similarity = cosine_similarity_model(sentence_embeddings[i], sentence_embeddings[j])\n",
    "        print(f\"'{sample_text[i]}', '{sample_text[j]}', similarity={similarity}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bebd7121",
   "metadata": {},
   "source": [
    "## Create model pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44912f6",
   "metadata": {},
   "source": [
    "### Preprocessing\n",
    "- Take the text from pandas\n",
    "- Run the model on all of the text\n",
    "- Record the embedding vectors in the dataframe\n",
    "- Perform KMeansClustering and record the cluster for each vector\n",
    "\n",
    "### Perform search\n",
    "- Create embeddings\n",
    "- Get cluster of embedding vectors\n",
    "- Find all text with the same cluster\n",
    "- Perform cosine similarity search between all elements in the cluster\n",
    "- Return the top K most elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "9ba5b181",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>overview</th>\n",
       "      <th>embeddings</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       title                                           overview  embeddings  \\\n",
       "0  Toy Story  Led by Woody, Andy's toys live happily in his ...         NaN   \n",
       "1    Jumanji  When siblings Judy and Peter discover an encha...         NaN   \n",
       "\n",
       "   cluster  \n",
       "0       -1  \n",
       "1       -1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"embeddings\"] = np.nan\n",
    "df[\"cluster\"] = -1\n",
    "\n",
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2c6ea6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "\n",
    "input_text = df[\"overview\"].values\n",
    "\n",
    "for i in range(0, len(input_text) // batch_size, batch_size):\n",
    "    batch = list(input_text[i:i + batch_size])\n",
    "    \n",
    "    batch_embeddings = create_embeddings(batch, tokenizer, text_model)\n",
    "    \n",
    "    print(batch_embeddings)\n",
    "    \n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p38",
   "language": "python",
   "name": "conda_pytorch_p38"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
